{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e40a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.family']=['Times New Roman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4299e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Hpv data\n",
    "file_address = '../Data/NassauCountyHPV.csv'\n",
    "\n",
    "df_hpv_nassau = pd.read_csv(file_address)\n",
    "\n",
    "file_address = '../Data/SuffolkCountyHPV.csv'\n",
    "\n",
    "df_hpv_suffolk = pd.read_csv(file_address)\n",
    "\n",
    "# Read TDAP data\n",
    "file_address = '../Data/NassauCountyTDAP.csv'\n",
    "\n",
    "df_tdap_nassau = pd.read_csv(file_address)\n",
    "\n",
    "file_address = '../Data/SuffolkCountyTDAP.csv'\n",
    "\n",
    "df_tdap_suffolk = pd.read_csv(file_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eda5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_address = '../Data/2022_2023Data/NassauCountyHPV2022_23.xlsx'\n",
    "\n",
    "df_hpv_nassau_22 = pd.read_excel(file_address)\n",
    "\n",
    "file_address = '../Data/2022_2023Data/NassauCountyTDAP2022_23.xlsx'\n",
    "\n",
    "df_tdap_nassau_22 = pd.read_excel(file_address)\n",
    "\n",
    "\n",
    "file_address = '../Data/2022_2023Data/SuffolkCountyHPV2022_23.xlsx'\n",
    "\n",
    "df_hpv_suffolk_22 = pd.read_excel(file_address)\n",
    "\n",
    "file_address = '../Data/2022_2023Data/SuffolkCountyTDAP2022_23.xlsx'\n",
    "\n",
    "df_tdap_suffolk_22 = pd.read_excel(file_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e45548",
   "metadata": {},
   "source": [
    "# Merge New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e280cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpv_n = pd.concat([df_hpv_nassau,df_hpv_nassau_22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfbd2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tdap_n = pd.concat([df_tdap_nassau,df_tdap_nassau_22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511bf2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tdap_s = pd.concat([df_tdap_suffolk,df_tdap_suffolk_22])\n",
    "df_hpv_s = pd.concat([df_hpv_suffolk,df_hpv_suffolk_22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec019bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpv_n.to_excel('../Data/Merged_data/NassauCountyHPV.xlsx',index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abcbe87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpv_s.to_excel('../Data/Merged_data/SuffolkCountyHPV.xlsx',index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cebbd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tdap_n.to_excel('../Data/Merged_data/NassauCountyTDAP.xlsx',index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67cd6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tdap_s.to_excel('../Data/Merged_data/SuffolkCountyTDAP.xlsx',index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbde35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0cec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00570deb",
   "metadata": {},
   "source": [
    "# Unique HPV Patients Data Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecf87b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename:\n",
    "\n",
    "df_hpv_nassau = df_hpv_n\n",
    "df_hpv_suffolk = df_hpv_s\n",
    "df_tdap_nassau = df_tdap_n\n",
    "df_tdap_suffok = df_tdap_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5094df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_address = '../Data/longislandzip.csv'\n",
    "\n",
    "df_zipcode = pd.read_csv(file_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80929817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data , drop N/A zipcode\n",
    "df_hpv_nassau.dropna(subset=['PatientZip'], inplace=True)\n",
    "df_hpv_suffolk.dropna(subset=['PatientZip'], inplace=True)\n",
    "df_tdap_nassau.dropna(subset=['PatientZip'], inplace=True)\n",
    "df_tdap_suffolk.dropna(subset=['PatientZip'], inplace=True)\n",
    "\n",
    "\n",
    "zips = np.array(df_zipcode['zip'])\n",
    "# Clean Data, drop zipcode not on the Long Island\n",
    "df_hpv_nassau = df_hpv_nassau[df_hpv_nassau['PatientZip'].isin(zips)]\n",
    "df_hpv_suffolk = df_hpv_suffolk[df_hpv_suffolk['PatientZip'].isin(zips)]\n",
    "df_tdap_nassau = df_tdap_nassau[df_tdap_nassau['PatientZip'].isin(zips)]\n",
    "df_tdap_suffolk = df_tdap_suffolk[df_tdap_suffolk['PatientZip'].isin(zips)]\n",
    "\n",
    "df_tdap = pd.concat([df_tdap_nassau,df_tdap_suffolk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62917140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate and prepare for the table generated\n",
    "df_tdap=pd.concat([df_tdap_nassau,df_tdap_suffolk])\n",
    "df_hpv = pd.concat([df_hpv_nassau,df_hpv_suffolk])\n",
    "df=pd.concat([df_hpv_nassau,df_hpv_suffolk,df_tdap_nassau,df_tdap_suffolk])\n",
    "\n",
    "df_tdap = df_tdap.sort_values(by=['vax_year','vax_month'],ascending=True)\n",
    "df_hpv = df_hpv.sort_values(by=['vax_year','vax_month'],ascending=True)\n",
    "df=df.sort_values(by=['vax_year','vax_month'],ascending=True)\n",
    "\n",
    "\n",
    "df_tdap_distinct = df_tdap.drop_duplicates(subset=['client_id'], keep='first')\n",
    "df_distinct = df.drop_duplicates(subset=['client_id'], keep='first')\n",
    "df_hpv_distinct = df_hpv.drop_duplicates(subset = ['client_id'],keep='first')\n",
    "\n",
    "\n",
    "df_hpv_distinct= df_hpv_distinct.reset_index()\n",
    "df_distinct= df_distinct.reset_index()\n",
    "df_tdap_distinct = df_tdap_distinct.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a226c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021,2022,2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete batch 0 add data 1859 rows\n",
      "complete batch 1 add data 1859 rows\n",
      "complete batch 2 add data 1859 rows\n",
      "complete batch 3 add data 1859 rows\n",
      "complete batch 4 add data 1859 rows\n",
      "complete batch 5 add data 1859 rows\n",
      "complete batch 6 add data 1859 rows\n",
      "complete batch 7 add data 1859 rows\n",
      "complete batch 8 add data 1859 rows\n",
      "complete batch 9 add data 1859 rows\n",
      "complete batch 10 add data 1859 rows\n",
      "complete batch 11 add data 1859 rows\n",
      "complete batch 12 add data 1859 rows\n",
      "complete batch 13 add data 1859 rows\n",
      "complete batch 14 add data 1859 rows\n",
      "complete batch 15 add data 1859 rows\n",
      "complete batch 16 add data 1859 rows\n",
      "complete batch 17 add data 1859 rows\n",
      "complete batch 18 add data 1859 rows\n",
      "complete batch 19 add data 1859 rows\n",
      "complete batch 20 add data 1859 rows\n",
      "complete batch 21 add data 1859 rows\n",
      "complete batch 22 add data 1859 rows\n",
      "complete batch 23 add data 1859 rows\n",
      "complete batch 24 add data 1859 rows\n",
      "complete batch 25 add data 1859 rows\n",
      "complete batch 26 add data 1859 rows\n",
      "complete batch 27 add data 1859 rows\n",
      "complete batch 28 add data 1859 rows\n",
      "complete batch 29 add data 1859 rows\n",
      "complete batch 30 add data 1859 rows\n",
      "complete batch 31 add data 1859 rows\n",
      "complete batch 32 add data 1859 rows\n",
      "complete batch 33 add data 1859 rows\n",
      "complete batch 34 add data 1859 rows\n",
      "complete batch 35 add data 1859 rows\n",
      "complete batch 36 add data 1859 rows\n",
      "complete batch 37 add data 1859 rows\n",
      "complete batch 38 add data 1859 rows\n",
      "complete batch 39 add data 1859 rows\n",
      "complete batch 40 add data 1859 rows\n",
      "complete batch 41 add data 1859 rows\n",
      "complete batch 42 add data 1859 rows\n",
      "complete batch 43 add data 1859 rows\n",
      "complete batch 44 add data 1859 rows\n",
      "complete batch 45 add data 1859 rows\n",
      "complete batch 46 add data 1859 rows\n",
      "complete batch 47 add data 1859 rows\n",
      "complete batch 48 add data 1859 rows\n",
      "complete batch 49 add data 1859 rows\n",
      "complete batch 50 add data 1859 rows\n",
      "complete batch 51 add data 1859 rows\n",
      "complete batch 52 add data 1859 rows\n",
      "complete batch 53 add data 1859 rows\n",
      "complete batch 54 add data 1859 rows\n",
      "complete batch 55 add data 1859 rows\n",
      "complete batch 56 add data 1859 rows\n",
      "complete batch 57 add data 1859 rows\n",
      "complete batch 58 add data 1859 rows\n",
      "complete batch 59 add data 1859 rows\n",
      "complete batch 60 add data 1859 rows\n",
      "complete batch 61 add data 1859 rows\n",
      "complete batch 62 add data 1859 rows\n",
      "complete batch 63 add data 1859 rows\n",
      "complete batch 64 add data 1859 rows\n",
      "complete batch 65 add data 1859 rows\n",
      "complete batch 66 add data 1859 rows\n",
      "complete batch 67 add data 1859 rows\n",
      "complete batch 68 add data 1859 rows\n",
      "complete batch 69 add data 1859 rows\n",
      "complete batch 70 add data 1859 rows\n",
      "complete batch 71 add data 1859 rows\n",
      "complete batch 72 add data 1859 rows\n",
      "complete batch 73 add data 1859 rows\n",
      "complete batch 74 add data 1859 rows\n",
      "complete batch 75 add data 1859 rows\n",
      "complete batch 76 add data 1859 rows\n",
      "complete batch 77 add data 1859 rows\n",
      "complete batch 78 add data 1859 rows\n",
      "complete batch 79 add data 1859 rows\n",
      "complete batch 80 add data 1859 rows\n",
      "complete batch 81 add data 1859 rows\n",
      "complete batch 82 add data 1859 rows\n",
      "complete batch 83 add data 1859 rows\n",
      "complete batch 84 add data 1859 rows\n",
      "complete batch 85 add data 1859 rows\n",
      "complete batch 86 add data 1859 rows\n",
      "complete batch 87 add data 1859 rows\n",
      "complete batch 88 add data 1859 rows\n",
      "complete batch 89 add data 1859 rows\n",
      "complete batch 90 add data 1859 rows\n",
      "complete batch 91 add data 1859 rows\n",
      "complete batch 92 add data 1859 rows\n",
      "complete batch 93 add data 1859 rows\n",
      "complete batch 94 add data 1859 rows\n",
      "complete batch 95 add data 1859 rows\n",
      "complete batch 96 add data 1859 rows\n",
      "complete batch 97 add data 1859 rows\n",
      "complete batch 98 add data 1859 rows\n",
      "complete batch 99 add data 1859 rows\n",
      "complete batch 100 add data 1859 rows\n",
      "complete batch 101 add data 1859 rows\n",
      "complete batch 102 add data 1859 rows\n",
      "complete batch 103 add data 1859 rows\n",
      "complete batch 104 add data 1859 rows\n",
      "complete batch 105 add data 1859 rows\n",
      "complete batch 106 add data 1859 rows\n",
      "complete batch 107 add data 1859 rows\n",
      "complete batch 108 add data 1859 rows\n",
      "complete batch 109 add data 1859 rows\n",
      "complete batch 110 add data 1859 rows\n",
      "complete batch 111 add data 1859 rows\n",
      "complete batch 112 add data 1859 rows\n",
      "complete batch 113 add data 1859 rows\n",
      "complete batch 114 add data 1859 rows\n",
      "complete batch 115 add data 1859 rows\n",
      "complete batch 116 add data 1859 rows\n",
      "complete batch 117 add data 1859 rows\n",
      "complete batch 118 add data 1859 rows\n",
      "complete batch 119 add data 1859 rows\n",
      "complete batch 120 add data 1859 rows\n",
      "complete batch 121 add data 1859 rows\n",
      "complete batch 122 add data 1859 rows\n",
      "complete batch 123 add data 1859 rows\n",
      "complete batch 124 add data 1859 rows\n",
      "complete batch 125 add data 1859 rows\n",
      "complete batch 126 add data 1859 rows\n",
      "complete batch 127 add data 1859 rows\n",
      "complete batch 128 add data 1859 rows\n",
      "complete batch 129 add data 1859 rows\n",
      "complete batch 130 add data 1859 rows\n",
      "complete batch 131 add data 1859 rows\n",
      "complete batch 132 add data 1859 rows\n",
      "complete batch 133 add data 1859 rows\n",
      "complete batch 134 add data 1859 rows\n",
      "complete batch 135 add data 1859 rows\n",
      "complete batch 136 add data 1859 rows\n",
      "complete batch 137 add data 1859 rows\n",
      "complete batch 138 add data 1859 rows\n",
      "complete batch 139 add data 1859 rows\n",
      "complete batch 140 add data 1859 rows\n",
      "complete batch 141 add data 1859 rows\n",
      "complete batch 142 add data 1859 rows\n",
      "complete batch 143 add data 1859 rows\n",
      "complete batch 144 add data 1859 rows\n",
      "complete batch 145 add data 1859 rows\n",
      "complete batch 146 add data 1859 rows\n",
      "complete batch 147 add data 1859 rows\n",
      "complete batch 148 add data 1859 rows\n",
      "complete batch 149 add data 1859 rows\n",
      "complete batch 150 add data 1859 rows\n",
      "complete batch 151 add data 1859 rows\n",
      "complete batch 152 add data 1859 rows\n",
      "complete batch 153 add data 1859 rows\n",
      "complete batch 154 add data 1859 rows\n",
      "complete batch 155 add data 1859 rows\n",
      "complete batch 156 add data 1859 rows\n",
      "complete batch 157 add data 1859 rows\n",
      "complete batch 158 add data 1859 rows\n",
      "complete batch 159 add data 1859 rows\n",
      "complete batch 160 add data 1859 rows\n",
      "complete batch 161 add data 1859 rows\n",
      "complete batch 162 add data 1859 rows\n",
      "complete batch 163 add data 1859 rows\n"
     ]
    }
   ],
   "source": [
    "#Total Table Generated\n",
    "\n",
    "tdap_table = pd.DataFrame(columns=['client_id', 'RACE_DESC', 'ETHNICITY_DESC','PatientZip','PatientCounty','GENDER',\n",
    "                                   2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015,\n",
    "                                   2016, 2017, 2018, 2019, 2020, 2021,2022,2023])\n",
    "cur = 0\n",
    "batches = len(df_tdap_distinct)//500\n",
    "for i in range(501):\n",
    "    tmp_df = df_tdap_distinct.iloc[cur:cur+batches]\n",
    "    final = cur + batches\n",
    "    if final > len(df_tdap_distinct):\n",
    "        final = len(df_tdap_distinct)\n",
    "    for j in range(cur,final):\n",
    "        tmp = {}\n",
    "        tmp['client_id'] = df_tdap_distinct['client_id'][j]\n",
    "        tmp['PatientZip'] = df_tdap_distinct['PatientZip'][j]\n",
    "        tmp['RACE_DESC'] = df_tdap_distinct['RACE_DESC'][j]\n",
    "        tmp['GENDER'] = df_tdap_distinct['GENDER'][j]\n",
    "        vax_year = df_tdap_distinct['vax_year'][j]\n",
    "        vax_age = df_tdap_distinct['PatientAge'][j]\n",
    "        for year in years:\n",
    "            if year<vax_year:\n",
    "                tmp[year] = np.nan\n",
    "            else:\n",
    "                tmp[year] = vax_age\n",
    "                vax_age += 1\n",
    "    #     print(tmp)\n",
    "        tmp_df = pd.DataFrame([tmp])\n",
    "        tdap_table = pd.concat([tdap_table, tmp_df], ignore_index=True)\n",
    "    tdap_table.to_csv('../Data/Merged_data/AgeOut_tdap.csv', mode='a', header=(i==0), index=False)\n",
    "    cur += batches\n",
    "    print('complete batch',i,'add data',len(tdap_table),'rows')\n",
    "    tdap_table = tdap_table.iloc[0:0]\n",
    "\n",
    "print(cur,final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_table = pd.DataFrame(columns=['client_id', 'PatientZip', 'RACE_DESC', 'GENDER',\n",
    "                               2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015,\n",
    "                               2016, 2017, 2018, 2019, 2020, 2021,2022,2023])\n",
    "batches= len(df_distinct)//500\n",
    "cur = 0\n",
    "for i in range(501):\n",
    "\n",
    "    tmp_df = df_distinct.iloc[cur:cur+batches]\n",
    "    final = cur + batches\n",
    "    if final > len(df_distinct):\n",
    "        final = len(df_distinct)\n",
    "    for j in range(cur,final):\n",
    "        tmp = {}\n",
    "        tmp['client_id'] = df_distinct['client_id'][j]\n",
    "        tmp['PatientZip'] = df_distinct['PatientZip'][j]\n",
    "        tmp['RACE_DESC'] = df_distinct['RACE_DESC'][j]\n",
    "        tmp['GENDER'] = df_distinct['GENDER'][j]\n",
    "        vax_year = df_distinct['vax_year'][j]\n",
    "        vax_age = df_distinct['PatientAge'][j]\n",
    "#         print(j)\n",
    "        for year in years:\n",
    "            if year<vax_year:\n",
    "                tmp[year] = np.nan\n",
    "            else:\n",
    "                tmp[year] = vax_age\n",
    "                vax_age += 1\n",
    "    #     print(tmp)\n",
    "        tmp_df = pd.DataFrame([tmp])\n",
    "        total_table = pd.concat([total_table, tmp_df], ignore_index=True)\n",
    "    total_table.to_csv('../Data/Merged_data/AgeOut_total.csv', mode='a', header=(i==0), index=False)\n",
    "    cur += batches\n",
    "    print('complete batch',i,'add data',len(total_table),'rows')\n",
    "    total_table = total_table.iloc[0:0]\n",
    "\n",
    "print(cur,final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c9c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpv_table = pd.DataFrame(columns=['client_id', 'PatientZip', 'RACE_DESC', 'GENDER',\n",
    "                               2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015,\n",
    "                               2016, 2017, 2018, 2019, 2020, 2021])\n",
    "batches= len(df_hpv_distinct)//500\n",
    "cur = 0\n",
    "for i in range(501):\n",
    "\n",
    "    tmp_df = df_hpv_distinct.iloc[cur:cur+batches]\n",
    "    final = cur + batches\n",
    "    if final > len(df_hpv_distinct):\n",
    "        final = len(df_hpv_distinct)\n",
    "    for j in range(cur,final):\n",
    "        tmp = {}\n",
    "        tmp['client_id'] = df_hpv_distinct['client_id'][j]\n",
    "        tmp['PatientZip'] = df_hpv_distinct['PatientZip'][j]\n",
    "        tmp['RACE_DESC'] = df_hpv_distinct['RACE_DESC'][j]\n",
    "        tmp['GENDER'] = df_hpv_distinct['GENDER'][j]\n",
    "        vax_year = df_hpv_distinct['vax_year'][j]\n",
    "        vax_age = df_hpv_distinct['PatientAge'][j]\n",
    "        for year in years:\n",
    "            if year<vax_year:\n",
    "                tmp[year] = np.nan\n",
    "            else:\n",
    "                tmp[year] = vax_age\n",
    "                vax_age += 1\n",
    "    #     print(tmp)\n",
    "        tmp_df = pd.DataFrame([tmp])\n",
    "        hpv_table = pd.concat([hpv_table, tmp_df], ignore_index=True)\n",
    "    hpv_table.to_csv('../Data/Merged_data/AgeOut_hpv.csv', mode='a', header=(i==0), index=False)\n",
    "    cur += batches\n",
    "    print('complete batch',i,'add data',len(hpv_table),'rows')\n",
    "    hpv_table = hpv_table.iloc[0:0]\n",
    "\n",
    "print(cur,final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
